% Encoding: UTF-8

@Article{Boyko2018,
  author   = {Nataliya Boyko; Oleg Basystiuk; Nataliya Shakhovska},
  date     = {2018-08-25},
  title    = {Performance Evaluation and Comparison of Software for Face Recognition, Based on Dlib and Opencv Library},
  abstract = {Overview and investigate time complexity of computer vision algorithms for face recognition. Main article idea is to compare two popular computer vision librarieobjs, they are OpenCV and dlib, explore features, analyze pros and cons each of them and understand in what situation each of them suit the best. Method. The technologies of computer vision, which are used for face recognition was worked out. Research of two popular computer vision libraries was conducted. Their features are analyzed and the advantages and disadvantages of each of them are estimated. Examples of building recognition application based on histogram-oriented gradients for face finding, face landmark estimation for face orientation, and deep convolutional neural network to compare with known faces. The article generalizes the concept of face recognition. The scientific basis for facial recognition and the construction of a complete recognition system was described. The basic principles of the programs for face recognition are formulated. A comparative analysis of the productivity of both libraries in relation to - the time of execution to the number of iterations of the applied algorithms was presented. Also built two simple applications for face recognition based on these libraries and comparing their performance.},
  keywords = {Performance, Dlib, Opencv},
}

@Article{Okumura2018,
  author   = {Akitoshi Okumura, Takamichi Hoshino, Susumu Handa, Eiko Yamada, Masahiro Tabuchi},
  date     = {2018},
  title    = {Identity Verification for Attendees of Large-scale Events Using Face Recognition of Selfies Taken with Smartphone Cameras},
  abstract = {This paper proposes an identity-verification system for attendees of large-scale events using face recognition from selfies taken with smartphone cameras. Such a system has been required to prevent illegal resale such as ticket scalping. The problem in verifying ticket holders is how to simultaneously verify identities efficiently and prevent individuals from impersonating others at a large-scale event at which tens of thousands of people participate. We developed two ticket ID systems for identifying the purchaser and holder of a ticket that uses two face-recognition systems, i.e., tablet-based and non-stop face-recognition systems that require ID equipment such as a tablet terminal with a camera, card reader, and ticket-issuing printer. Since these systems were proven effective for preventing illegal resale by verifying attendees at large concerts of popular music groups, they have been used at more than 100 concerts. However, simplifying the ID equipment is necessary from an operational view-point. It is also necessary to secure clear facial photos from a technical view-point of face-recognition accuracy because face recognition fails when unclear face photos are obtained, i.e., when individuals have their eyes closed, not looking directly forward, or have hair covering their faces. We proposed a system that uses attendees' selfies as input photos for face recognition, which simplifies ID equipment by only requiring smartphone cameras, enabling clear face photos to be obtained the allowing attendees to take their own photos. The system achieved 97.5% face-recognition accuracy in preliminary tests of 240 photos taken under various brightness and background conditions.},
  keywords = {Face Recognition, Events,},
}

@Article{Gorodnichy2020,
  author   = {D.O. Gorodnichy},
  date     = {2020},
  title    = {Video-based framework for face recognition in video},
  abstract = {This paper presents a number of new views and techniques claimed to be very important for the problem of face recognition in video (FRiV). First, a clear differentiation is made between photographic facial data and video-acquired facial data as being two different modalities: one providing hard biometrics, the other providing softer biometrics. Second, faces which have the resolution of at least 12 pixels between the eyes are shown to be recognizable by computers just as they are by humans. As a way to deal with low resolution and quality of each individual video frame, the paper offers to use the neuro-associative principle employed by human brain, according to which both memorization and recognition of data are done based on a flow of frames rather than on one frame: synaptic plasticity provides a way to memorize from a sequence, while the collective decision making over time is very suitable for recognition of a sequence. As a benchmark for FRiV approaches, the paper introduces the IIT-NRC video-based database of faces which consists of pairs of low-resolution video clips of unconstrained facial motions. The recognition rate of over 95%, which we achieve on this database, as well as the results obtained on real-time annotation of people on TV allow us to believe that the proposed framework brings us closer to the ultimate benchmark for the FRiV approaches, which is "if you are able to recognize a person, so should the computer".},
  keywords = {AI, Video, vergelijken},
}

@Article{Stallkamp2012,
  author   = {Johannes Stallkamp; Hazim K. Ekenel; Rainer Stiefelhagen},
  date     = {2012},
  title    = {Video-based Face Recognition on Real-World Data},
  abstract = {In this paper, we present the classification sub-system of a real-time video-based face identification system which recognizes people entering through the door of a laboratory. Since the subjects are not asked to cooperate with the system but are allowed to behave naturally, this application scenario poses many challenges. Continuous, uncontrolled variations of facial appearance due to illumination, pose, expression, and occlusion need to be handled to allow for successful recognition. Faces are classified by a local appearance-based face recognition algorithm. The obtained confidence scores from each classification are progressively combined to provide the identity estimate of the entire sequence. We introduce three different measures to weight the contribution of each individual frame to the overall classification decision. They are distance- to-model (DTM), distance-to-second-closest (DT2ND), and their combination. Both a k-nearest neighbor approach and a set of Gaussian mixtures are evaluated to produce individual frame scores. We have conducted closed set and open set identification experiments on a database of 41 subjects. The experimental results show that the proposed system is able to reach high correct recognition rates in a difficult scenario.},
  keywords = {AI, real-time, video},
}

@Article{Soe2021,
  author   = {Than Htut Soe},
  date     = {2021},
  title    = {AI video editing tools},
  abstract = {Video editing can be a very tedious task, so unsurprisingly Artificial Intelligence has been increasingly used to streamline the workflow or automate
away tedious tasks. However, it is very difficult
to get an overview of what intelligent video editing tools are in the research literature and needs for
automation from the video editors. So, we identified the field of intelligent video editing tools in
research, and we survey the opinions of professional video editors. We have also summarized current state of the art in artificial intelligence research
with the intention of identifying what are the possibilities and current technical limits towards truly
intelligent video editing tools. The findings contribute towards understanding of the field of intelligent video editing tools, highlights unaddressed
automation needs by the survey and provides general suggestions for further research in intelligent
video editing tools},
  keywords = {AI tools, video editing, state of the art},
}

@Article{IgorBieda,
  author   = {Igor Bieda, Taras Panchenko},
  date     = {maart 2022},
  title    = {A Systematic Mapping Study on Artificial Intelligence Tools Usedin Video Editing},
  abstract = {From the past two eras, artificial intelligence has gained the
attention of researchers of all research areas. Video editing is a
task in the list that starts leveraging the blessing of Artificial
Intelligence (AI). Since AI promises to make technology better
use of human life although video editing technology is not new
yet it is adopting new technologies like AI to become more
powerful and sophisticated for video editors as well as users.
Like other technologies, video editing will also be facilitated by
the majestic power of AI in near future. There has been a lot of
research that uses AI in video editing, yet there is no
comprehensive literature review that systematically finds all of
this work on one page so that new researchers can find research
gaps in that area. In this research we conducted a statically
approach called, systematic mapping study, to find answers to
pre-proposed research questions. The aim and objective of this
research are to find research gaps in our topic under discussion},
  keywords = {video editing, AI tools},
}

@Comment{jabref-meta: databaseType:biblatex;}
